cap = cv2.VideoCapture(0)

while(1):
    _, gbr1 = cap.read()

    gbr1 = frame.to_ndarray(format="bgr24")
            kao = HaarCascade.detectMultiScale(gbr1,1.1,4)

            if len(kao)>0:
                x1, y1, width, height = kao[0]
            else:
                x1, y1, width, height = 1, 1, 10, 10

            x1, y1 = abs(x1), abs(y1)
            x2, y2 = x1 + width, y1 + height


            gbr = cv2.cvtColor(gbr1, cv2.COLOR_BGR2RGB)
            gbr = Image.fromarray(gbr)
            gbr_array = asarray(gbr)

            face = gbr_array[y1:y2, x1:x2]

            face = Image.fromarray(face)
            face = face.resize((160,160))
            face = asarray(face)


            face = expand_dims(face, axis=0)
            signature = MyFaceNet.embeddings(face)

            min_dist=100
            identity=' '
            for key, value in database.items() :
                dist = np.linalg.norm(value-signature)
                if dist < min_dist:
                    min_dist = dist
                    identity = key

            cv2.putText(gbr1,identity, (100,100),cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2, cv2.LINE_AA)
            cv2.rectangle(gbr1,(x1,y1),(x2,y2), (0,255,0), 2)

            new_frame = VideoFrame.from_ndarray(gbr1, format="bgr24")
            new_frame.pts = frame.pts
            new_frame.time_base = frame.time_base

            return new_frame